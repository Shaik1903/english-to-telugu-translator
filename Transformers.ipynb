{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSti8lP9rs+zDbGmOZfPIn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dc861517d3c04382a905ac6c0b9209a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_067b6623c7604eb0b9788b0e03a3c2ed",
              "IPY_MODEL_f515082e4007434ba8d25f07f5389654",
              "IPY_MODEL_afe578e0b2b04fcfac844c2c55eabaf8"
            ],
            "layout": "IPY_MODEL_7e9330524b684dd0afcf79d48adead04"
          }
        },
        "067b6623c7604eb0b9788b0e03a3c2ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a250f24d3f44dc8b2b39026c30b5846",
            "placeholder": "​",
            "style": "IPY_MODEL_13c0db0a71344ba4a6e5498927453120",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "f515082e4007434ba8d25f07f5389654": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1fe7306a6814ed7b434c7ae854f322e",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a2f39fc2d93e4515a4d10c72346d5bde",
            "value": 29
          }
        },
        "afe578e0b2b04fcfac844c2c55eabaf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cb1a793fb414449b3b49c90157d2f20",
            "placeholder": "​",
            "style": "IPY_MODEL_afaf31eae64c46b78a0109a523120d37",
            "value": " 29.0/29.0 [00:00&lt;00:00, 487B/s]"
          }
        },
        "7e9330524b684dd0afcf79d48adead04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a250f24d3f44dc8b2b39026c30b5846": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13c0db0a71344ba4a6e5498927453120": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1fe7306a6814ed7b434c7ae854f322e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2f39fc2d93e4515a4d10c72346d5bde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9cb1a793fb414449b3b49c90157d2f20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afaf31eae64c46b78a0109a523120d37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f01a9022caab40a7b47ef9b754f8fbcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fbe91290ee76437a9938af1982cbe474",
              "IPY_MODEL_686cca9d55ba4af6bc75e884d35afff6",
              "IPY_MODEL_8cc4d7899dfe450787aa81a35ad0e364"
            ],
            "layout": "IPY_MODEL_5d4dd4d84dcd4159a1f90962eedd5e8c"
          }
        },
        "fbe91290ee76437a9938af1982cbe474": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c34221430b134a8bbb4cbbaf63dde094",
            "placeholder": "​",
            "style": "IPY_MODEL_73a7d0bb376b4e0ca10a05090a96e4af",
            "value": "vocab.txt: 100%"
          }
        },
        "686cca9d55ba4af6bc75e884d35afff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c9541c51c71414f9caaeb7c2f081ae6",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_74c527ae1e9b4b38afc2daad7ad58d8b",
            "value": 995526
          }
        },
        "8cc4d7899dfe450787aa81a35ad0e364": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc1811a481d046049ca35b92c1c96b3a",
            "placeholder": "​",
            "style": "IPY_MODEL_7d0e5aa45bd245c1bb7be60b5c01936b",
            "value": " 996k/996k [00:00&lt;00:00, 2.10MB/s]"
          }
        },
        "5d4dd4d84dcd4159a1f90962eedd5e8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c34221430b134a8bbb4cbbaf63dde094": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73a7d0bb376b4e0ca10a05090a96e4af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c9541c51c71414f9caaeb7c2f081ae6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74c527ae1e9b4b38afc2daad7ad58d8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc1811a481d046049ca35b92c1c96b3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d0e5aa45bd245c1bb7be60b5c01936b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9855b640a0424ce1b558c13a796f2075": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_afe013d3174d462e90c01819e0f9c728",
              "IPY_MODEL_d6c6d96cc1b740a2a845ba6d4ab8b831",
              "IPY_MODEL_818e55ca32b84d18a35593c935b86c66"
            ],
            "layout": "IPY_MODEL_c5f206b815b949d1b2237006d198e4eb"
          }
        },
        "afe013d3174d462e90c01819e0f9c728": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69f2a087f1c5439b9cd7106bb24d25b6",
            "placeholder": "​",
            "style": "IPY_MODEL_e13faab9dd3b4948b11baf62e7024a09",
            "value": "tokenizer.json: 100%"
          }
        },
        "d6c6d96cc1b740a2a845ba6d4ab8b831": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bcafd1271f64d80b160865ab9c17925",
            "max": 1961828,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e69f62e30c0a4de283e36771f4afeed0",
            "value": 1961828
          }
        },
        "818e55ca32b84d18a35593c935b86c66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf1e93cac2084fd0ae1eb4757bd28c2e",
            "placeholder": "​",
            "style": "IPY_MODEL_87f8730d10374f6eaf3480948fb5b87d",
            "value": " 1.96M/1.96M [00:00&lt;00:00, 8.56MB/s]"
          }
        },
        "c5f206b815b949d1b2237006d198e4eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69f2a087f1c5439b9cd7106bb24d25b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e13faab9dd3b4948b11baf62e7024a09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bcafd1271f64d80b160865ab9c17925": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e69f62e30c0a4de283e36771f4afeed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf1e93cac2084fd0ae1eb4757bd28c2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87f8730d10374f6eaf3480948fb5b87d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e60686f16134451d8e9837ec1c622174": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d724dae4debf41518ee6049c896b66de",
              "IPY_MODEL_6ccacb1ce1f04976a6545f8b2cbc3c72",
              "IPY_MODEL_723fe780722e4298a93c2b99544225eb"
            ],
            "layout": "IPY_MODEL_f440e93464d6416e8569416a57ea4503"
          }
        },
        "d724dae4debf41518ee6049c896b66de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb8d3c284e264ad2b88d8e460675b544",
            "placeholder": "​",
            "style": "IPY_MODEL_09d2708e6c6848a9904d5b49c1506cc6",
            "value": "config.json: 100%"
          }
        },
        "6ccacb1ce1f04976a6545f8b2cbc3c72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18e4b7a6341949139bc4c29e6b474e32",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_75c08f9ebbe94d23a584f39f5f980b81",
            "value": 625
          }
        },
        "723fe780722e4298a93c2b99544225eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8343b393984248c6967932980ea8323b",
            "placeholder": "​",
            "style": "IPY_MODEL_b22ae9ebf7664ced9fa262f7cda30bc8",
            "value": " 625/625 [00:00&lt;00:00, 20.1kB/s]"
          }
        },
        "f440e93464d6416e8569416a57ea4503": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb8d3c284e264ad2b88d8e460675b544": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09d2708e6c6848a9904d5b49c1506cc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18e4b7a6341949139bc4c29e6b474e32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75c08f9ebbe94d23a584f39f5f980b81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8343b393984248c6967932980ea8323b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b22ae9ebf7664ced9fa262f7cda30bc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shaik1903/english-to-telugu-translator/blob/main/Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Sentence Embedding Function\n",
        "Replace with the HF tokernizers or create one\n",
        "'''"
      ],
      "metadata": {
        "id": "wor3F1rlOHfs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "481e75ca-8cb3-4bd0-8278-d655971445d7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nSentence Embedding Function\\nReplace with the HF tokernizers or create one\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "C5Ysw05MXUxD"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsuDNbXSecsr",
        "outputId": "4f3c4245-01e6-4cb2-c531-0d362536a5d7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english_file = '/content/drive/MyDrive/Projects/English to Telugu Translator/train.en'\n",
        "telugu_file = '/content/drive/MyDrive/Projects/English to Telugu Translator/train.te'"
      ],
      "metadata": {
        "id": "xNfM3r4zecvg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "START_TOKEN = ''\n",
        "PADDING_TOKEN = ''\n",
        "END_TOKEN = ''\n",
        "english_vocabulary = [START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/',\n",
        "                        '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
        "                        ':', '<', '=', '>', '?', '@',\n",
        "                        '[', '\\\\', ']', '^', '_', '`',\n",
        "                        'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
        "                        'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x',\n",
        "                        'y', 'z',\n",
        "                        '{', '|', '}', '~', PADDING_TOKEN, END_TOKEN]\n",
        ""
      ],
      "metadata": {
        "id": "E1C9bg7qGh-J"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "telugu_vocabulary = [START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/',\n",
        "                     '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '<', '=', '>', '?', 'ˌ',\n",
        "                     'ఁ', 'ఆ', 'ఇ', 'ా', 'ి', 'ీ', 'ు', 'ూ',\n",
        "                     'అ', 'ఆ', 'ఇ', 'ఈ', 'ఉ', 'ఊ', 'ఋ', 'ౠ', 'ఌ', 'ఎ', 'ఏ', 'ఐ', 'ఒ', 'ఓ', 'ఔ',\n",
        "                     'క', 'ఖ', 'గ', 'ఘ', 'ఙ',\n",
        "                     'చ', 'ఛ', 'జ', 'ఝ', 'ఞ',\n",
        "                     'ట', 'ఠ', 'డ', 'ఢ', 'ణ',\n",
        "                     'త', 'థ', 'ద', 'ధ', 'న',\n",
        "                     'ప', 'ఫ', 'బ', 'భ', 'మ',\n",
        "                     'య', 'ర', 'ల', 'వ', 'శ', 'ష', 'స', 'హ', 'క్ష', 'ళ', 'ఱ',\n",
        "                     '఼', 'ఽ', 'ా', 'ి', 'ీ', 'ు', 'ూ', 'ృ', 'ౄ', 'ె', 'ే', 'ై', 'ొ', 'ో', 'ౌ', '్', 'ౕ', 'ౖ', '౞', 'ౣ', 'ం', 'ః',\n",
        "                     '౦', '౧', '౨', '౩', '౪', '౫', '౬', '౭', '౮', '౯', PADDING_TOKEN, END_TOKEN]\n"
      ],
      "metadata": {
        "id": "MQjzOaUpGiBC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_telugu = {k:v for k,v in enumerate(telugu_vocabulary)}\n",
        "telugu_to_index = {v:k for k,v in enumerate(telugu_vocabulary)}\n",
        "index_to_english = {k:v for k,v in enumerate(english_vocabulary)}\n",
        "english_to_index = {v:k for k,v in enumerate(english_vocabulary)}"
      ],
      "metadata": {
        "id": "9TsY39f6ecyT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(english_file, 'r') as file:\n",
        "    english_sentences = file.readlines()\n",
        "with open(telugu_file, 'r') as file:\n",
        "    telugu_sentences = file.readlines()"
      ],
      "metadata": {
        "id": "UBHXEfKLec3D"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Limit Number of sentences\n",
        "TOTAL_SENTENCES = 4300\n",
        "english_sentences = english_sentences[:TOTAL_SENTENCES]\n",
        "telugu_sentences = telugu_sentences[:TOTAL_SENTENCES]\n",
        "english_sentences = [sentence.rstrip('\\n').lower() for sentence in english_sentences]   # This removes the newline character and converts all of the words into lower case\n",
        "telugu_sentences = [sentence.rstrip('\\n') for sentence in telugu_sentences]"
      ],
      "metadata": {
        "id": "ql9PIPrNec59"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_sentences[-5:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXkoQGh3ec9F",
        "outputId": "5098ab11-e73c-4831-f1fe-6f66e0f67485"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['belgian congolese forces under the command of belgian officers notably fought against the italian colonial army in ethiopia in asosa, borta and sao under major-general auguste-eduard gilliaert during the second east african campaign.',\n",
              " 'dont slog too much',\n",
              " 'doctors advised him for a few days rest.',\n",
              " '( 1) foreseeing dangerous situations and avoiding them.',\n",
              " 'this implies an argument of perigee of either 0 or 180.']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "telugu_sentences[-5:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5imZTwQ9fznm",
        "outputId": "718bae40-eba5-43f1-bc88-9bcb27272986"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['బెల్జియన్ అధికారుల ఆధ్వర్యంలో బెల్జియన్ కాంగో దళాలు ప్రత్యేకంగా రెండో తూర్పు ఆఫ్రికన్ పోరాటసమయంలో మేజర్-జనరల్ అగస్టే-ఎడార్డ్ గిల్లియాట్, సాయో నేతృత్వంలోని అస్సోసాలో (ఇథియోపియాలోని) ఇటాలియన్ వలస సైన్యంపై పోరాడారు.',\n",
              " 'ఎక్కువ బ్రష్ చేయకండి',\n",
              " 'కొన్ని రోజులపాటు విశ్రాంతి అవసరమని వైద్యులు తెలిపారు.',\n",
              " '( 1) ప్రమాదాలను ముందే పసిగట్టి తప్పించుకోవడం.',\n",
              " 'అంటే దానర్థం, పెరిజీ ఆర్గ్యుమెంటు 0 డిగ్రీలు గాని, 180 డిగ్రీలుగానీ ఉండాలి.']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_length = 200\n",
        "\n",
        "def is_valid_tokens(sentence, vocab):\n",
        "    for token in list(set(sentence)):\n",
        "        if token not in vocab:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def is_valid_length(sentence, max_sequence_length):\n",
        "    return len(list(sentence)) < (max_sequence_length - 1) # need to re-add the end token so leaving 1 space\n",
        "\n",
        "valid_sentence_indicies = []\n",
        "for i in range(len(telugu_sentences)):\n",
        "    telugu_sentence, english_sentence = telugu_sentences[i], english_sentences[i]\n",
        "    if is_valid_length(telugu_sentence, max_sequence_length) and is_valid_length(english_sentence, max_sequence_length) and is_valid_tokens(telugu_sentence, telugu_vocabulary):\n",
        "        valid_sentence_indicies.append(i)\n",
        "\n",
        "print(f\"Number of sentences: {len(telugu_sentences)}\")\n",
        "print(f\"Number of valid sentences: {len(valid_sentence_indicies)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKvRAEO2fzqt",
        "outputId": "aa4e1f67-94f8-47fe-c82f-a24ba4891d5c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentences: 4300\n",
            "Number of valid sentences: 3275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "telugu_sentences = [telugu_sentences[i] for i in valid_sentence_indicies]\n",
        "english_sentences = [english_sentences[i] for i in valid_sentence_indicies]"
      ],
      "metadata": {
        "id": "IXlXq8A_fzue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "\n",
        "    def __init__(self, english_sentences, telugu_sentences):\n",
        "        self.english_sentences = english_sentences\n",
        "        self.kannada_sentences = telugu_sentences\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.english_sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.english_sentences[idx], self.kannada_sentences[idx]"
      ],
      "metadata": {
        "id": "A6EHYoYFec_V"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TextDataset(english_sentences, telugu_sentences)"
      ],
      "metadata": {
        "id": "g6E4svwDr48x"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dczd3cq1r4_1",
        "outputId": "52d4c7aa-09d6-4c19-f0bf-169ef5d040d4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4300"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUyoGKiDr5Cc",
        "outputId": "81c57d26-7190-4a3f-a412-9be808cfcf10"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('how do we glorify jehovahs undeserved kindness?',\n",
              " 'యెహోవా కృపను మనమెలా మహిమపరచవచ్చు?')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 3\n",
        "train_loader = DataLoader(dataset, batch_size)\n",
        "iterator = iter(train_loader)"
      ],
      "metadata": {
        "id": "7-SYisvMr5Fs"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_num, batch in enumerate(iterator):\n",
        "    print(batch)\n",
        "    if batch_num > 1:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s02q3FI0sLAw",
        "outputId": "fcaeecac-9c9c-446f-c974-d910083e6fae"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('in monaco-ville, street signs are printed in both french and mongasque.', 'the same has been confirmed in a report carried by bbc.', \"i said, 'who are you?'\"), ('మొనాకో-విల్లెలో, ఫ్రెంచ్, మోనెగస్క్యూ రెండింటిలో వీధి చిహ్నాలను ప్రింట్ చేస్తారు.', 'ప్రముఖ బీబీసీ నివేదిక ఇదే విషయం పేర్కొంది.', \"'ఎవరు మీరు' అన్నాను.\")]\n",
            "[('in this state they can easily survive one year or longer.', 'the complete details of his death are yet to be known.', 'if you go...'), ('సంవత్సరానికి అదనంగా ఒక రోజునో లేక ఒక నెలనో చేర్చి ఈ తేడాను నివారించవచ్చు.', 'వీరి మరణానికి సంబంధించి పూర్తి వివరాలు ఇంకా తెలియాల్సి ఉంది.', 'రథము వెడలె .')]\n",
            "[('\"all the very best.\"\"\"', 'what is this, child?', 'speaking during another session on reducing poverty through social and economic transformation, shri gangwar the government of india, under the leadership of prime minister shri narendra modi, is committed to eradicate poverty and promote prosperity in a changing world'), ('ఆల్ ది బెస్ట్\\u200c”అని అన్నారు.', 'ఏంటిది చిన్న పిల్లాడిలా?', 'సామాజిక, ఆర్థిక పరివర్తన ద్వారా పేదరికాన్ని తగ్గించడంపై మరో సెషన్\\u200cలో మాట్లాడుతూ, ప్రధానమంత్రి శ్రీ నరేంద్రమోదీ నాయకత్వంలో భారత ప్రభుత్వం పేదరిక నిర్మూలనకు మరియు మారుతున్న ప్రపంచంలో శ్రేయస్సును ప్రోత్సహించడానికి కట్టుబడి ఉందని\\xa0\\xa0శ్రీ గంగ్వార్ అన్నారు.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def tokenize(sentence, language_to_index, start_token=True, end_token=True):\n",
        "    sentence_word_indicies = [language_to_index[token] for token in list(sentence)]\n",
        "    if start_token:\n",
        "        sentence_word_indicies.insert(0, language_to_index[START_TOKEN])\n",
        "    if end_token:\n",
        "        sentence_word_indicies.append(language_to_index[END_TOKEN])\n",
        "    for _ in range(len(sentence_word_indicies), max_sequence_length):\n",
        "        sentence_word_indicies.append(language_to_index[PADDING_TOKEN])\n",
        "    return torch.tensor(sentence_word_indicies)"
      ],
      "metadata": {
        "id": "KkzSvGqqsLFS"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9X654bUesLHi",
        "outputId": "56bed1c3-814e-41ba-f5d2-6ec870d253e7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('\"all the very best.\"\"\"',\n",
              "  'what is this, child?',\n",
              "  'speaking during another session on reducing poverty through social and economic transformation, shri gangwar the government of india, under the leadership of prime minister shri narendra modi, is committed to eradicate poverty and promote prosperity in a changing world'),\n",
              " ('ఆల్ ది బెస్ట్\\u200c”అని అన్నారు.',\n",
              "  'ఏంటిది చిన్న పిల్లాడిలా?',\n",
              "  'సామాజిక, ఆర్థిక పరివర్తన ద్వారా పేదరికాన్ని తగ్గించడంపై మరో సెషన్\\u200cలో మాట్లాడుతూ, ప్రధానమంత్రి శ్రీ నరేంద్రమోదీ నాయకత్వంలో భారత ప్రభుత్వం పేదరిక నిర్మూలనకు మరియు మారుతున్న ప్రపంచంలో శ్రేయస్సును ప్రోత్సహించడానికి కట్టుబడి ఉందని\\xa0\\xa0శ్రీ గంగ్వార్ అన్నారు.')]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''ఇది ఒక ఉదాహరణ'''\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "dc861517d3c04382a905ac6c0b9209a9",
            "067b6623c7604eb0b9788b0e03a3c2ed",
            "f515082e4007434ba8d25f07f5389654",
            "afe578e0b2b04fcfac844c2c55eabaf8",
            "7e9330524b684dd0afcf79d48adead04",
            "6a250f24d3f44dc8b2b39026c30b5846",
            "13c0db0a71344ba4a6e5498927453120",
            "d1fe7306a6814ed7b434c7ae854f322e",
            "a2f39fc2d93e4515a4d10c72346d5bde",
            "9cb1a793fb414449b3b49c90157d2f20",
            "afaf31eae64c46b78a0109a523120d37",
            "f01a9022caab40a7b47ef9b754f8fbcc",
            "fbe91290ee76437a9938af1982cbe474",
            "686cca9d55ba4af6bc75e884d35afff6",
            "8cc4d7899dfe450787aa81a35ad0e364",
            "5d4dd4d84dcd4159a1f90962eedd5e8c",
            "c34221430b134a8bbb4cbbaf63dde094",
            "73a7d0bb376b4e0ca10a05090a96e4af",
            "0c9541c51c71414f9caaeb7c2f081ae6",
            "74c527ae1e9b4b38afc2daad7ad58d8b",
            "bc1811a481d046049ca35b92c1c96b3a",
            "7d0e5aa45bd245c1bb7be60b5c01936b",
            "9855b640a0424ce1b558c13a796f2075",
            "afe013d3174d462e90c01819e0f9c728",
            "d6c6d96cc1b740a2a845ba6d4ab8b831",
            "818e55ca32b84d18a35593c935b86c66",
            "c5f206b815b949d1b2237006d198e4eb",
            "69f2a087f1c5439b9cd7106bb24d25b6",
            "e13faab9dd3b4948b11baf62e7024a09",
            "7bcafd1271f64d80b160865ab9c17925",
            "e69f62e30c0a4de283e36771f4afeed0",
            "cf1e93cac2084fd0ae1eb4757bd28c2e",
            "87f8730d10374f6eaf3480948fb5b87d",
            "e60686f16134451d8e9837ec1c622174",
            "d724dae4debf41518ee6049c896b66de",
            "6ccacb1ce1f04976a6545f8b2cbc3c72",
            "723fe780722e4298a93c2b99544225eb",
            "f440e93464d6416e8569416a57ea4503",
            "eb8d3c284e264ad2b88d8e460675b544",
            "09d2708e6c6848a9904d5b49c1506cc6",
            "18e4b7a6341949139bc4c29e6b474e32",
            "75c08f9ebbe94d23a584f39f5f980b81",
            "8343b393984248c6967932980ea8323b",
            "b22ae9ebf7664ced9fa262f7cda30bc8"
          ]
        },
        "id": "1oiaYd9k06uF",
        "outputId": "565cf359-0708-44eb-d81d-da6f8ced66b7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc861517d3c04382a905ac6c0b9209a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f01a9022caab40a7b47ef9b754f8fbcc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9855b640a0424ce1b558c13a796f2075"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e60686f16134451d8e9837ec1c622174"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example sentence\n",
        "sentence = \"సామాజిక, ఆర్థిక పరివర్తన ద్వారా పేదరికాన్ని తగ్గించడంపై మరో సెషన్\\u200cలో మాట్లాడుతూ, ప్రధానమంత్రి శ్రీ నరేంద్రమోదీ నాయకత్వంలో భారత ప్రభుత్వం పేదరిక నిర్మూలనకు మరియు మారుతున్న ప్రపంచంలో శ్రేయస్సును ప్రోత్సహించడానికి కట్టుబడి ఉందని\\xa0\\xa0శ్రీ గంగ్వార్ అన్నారు.\"\n",
        "\n",
        "# Encode the sentence with start and end tokens (no [CLS] token), and padding\n",
        "encoded_dict = tokenizer.encode_plus(\n",
        "    sentence,\n",
        "    add_special_tokens=True,  # Add [SEP] token\n",
        "    max_length=200,           # Set the maximum length to 512\n",
        "    pad_to_max_length=True,   # Pad the sequence to the maximum length\n",
        "    return_attention_mask=True,  # Generate attention mask\n",
        "    return_tensors='pt',      # Return PyTorch tensors\n",
        "    cls_token=None,           # Do not add the [CLS] token\n",
        "    truncation=True           # Truncate or pad to the specified max_length\n",
        ")\n",
        "\n",
        "# Access the encoded tokens and attention mask\n",
        "input_ids = encoded_dict['input_ids']\n",
        "attention_mask = encoded_dict['attention_mask']\n",
        "\n",
        "# Print the encoded tokens and attention mask\n",
        "print(\"Input IDs:\", input_ids)\n",
        "print(\"Attention Mask:\", attention_mask)\n"
      ],
      "metadata": {
        "id": "yCCNiUrD1E6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokeniz(sentence,special_tokens = False):\n",
        "  encoded_dict = tokenizer.encode_plus(\n",
        "    sentence,\n",
        "    add_special_tokens=special_tokens,  # Add [SEP] token\n",
        "    max_length=200,           # Set the maximum length to 512\n",
        "    pad_to_max_length=True,   # Pad the sequence to the maximum length\n",
        "    return_attention_mask=True,  # Generate attention mask\n",
        "    return_tensors='pt',      # Return PyTorch tensors\n",
        "    cls_token=None,           # Do not add the [CLS] token\n",
        "    truncation=True           # Truncate or pad to the specified max_length\n",
        "    )\n",
        "  input_ids = encoded_dict['input_ids']\n",
        "  return input_ids"
      ],
      "metadata": {
        "id": "sFHYPAsL1GZa"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng_tokenized, tl_tokenized = [], []\n",
        "for sentence_num in range(batch_size):\n",
        "    eng_sentence, tl_sentence = batch[0][sentence_num], batch[1][sentence_num]\n",
        "    eng_tokenized.append( tokeniz(eng_sentence, False) )\n",
        "    tl_tokenized.append( tokeniz(tl_sentence,True) )\n",
        "eng_tokenized = torch.stack(eng_tokenized)\n",
        "tl_tokenized = torch.stack(tl_tokenized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pbdkpm7tsLJw",
        "outputId": "69ba9788-dcad-4aa0-9a78-8ae4c2a9b734"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Keyword arguments {'cls_token': None} not recognized.\n",
            "Keyword arguments {'cls_token': None} not recognized.\n",
            "Keyword arguments {'cls_token': None} not recognized.\n",
            "Keyword arguments {'cls_token': None} not recognized.\n",
            "Keyword arguments {'cls_token': None} not recognized.\n",
            "Keyword arguments {'cls_token': None} not recognized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tl_tokenized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkdvKuCFsLNC",
        "outputId": "e2fd7cab-1a8c-4f67-dd18-05acf8ff24d5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[   101,   1189,  15959,  35764,   1222,  72799,  20147,    100,\n",
              "           29030,   1188,  37218,  27374,    119,    102,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0]],\n",
              "\n",
              "        [[   101,   1196,  69340,  19541,  74711,  75099,  15959,  46565,\n",
              "           22012,  46565,    136,    102,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0]],\n",
              "\n",
              "        [[   101,  18620,    117,   1189,  15695,  72234,  40469,   1220,\n",
              "           20347,  18892,  15695,  78127,  14454,   1220,  17729,  41772,\n",
              "           96756,  31114,   1215, 104533,  79272,  65232,  59041,   1224,\n",
              "           77277,   1233,  37637,  73950,  11510,   1224,  15735, 105502,\n",
              "           32155,  91753,    117,  27307,  70390,  88046,  46096,   1219,\n",
              "           20518,  17729, 108696,  52798,  24696,  21120,  41772,  18564,\n",
              "            1219,  15735,  19161,  15280,  81797,  11510,  22869,  37272,\n",
              "            1220,  17729,  41772,  20347,  15280,   1219,  15868,  15695,\n",
              "           24696,  25366,  13302,  13179,  15382,  12788,   1224,  27374,\n",
              "           44275,  94504,  33364,   1231,  52798,  17729,  19161,  15370,\n",
              "           39179,  14314,   1220,  52798,  21120,  49184,  61924,  99670,\n",
              "           15868,  91178,   1201,  99387, 111337,  22012,   1192, 108696,\n",
              "           13907,  46096,   1203,  30164,  18892,  67787,  24835,   1188,\n",
              "           37218,  27374,    119,    102,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0,\n",
              "               0,      0,      0,      0,      0,      0,      0,      0]]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AUkNfuzisLQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Dataset\n",
        "# Create Dataloaders"
      ],
      "metadata": {
        "id": "CvuVz8MDWGy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_sequence_length):\n",
        "        super().__init__()\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self):\n",
        "        even_i = torch.arange(0, self.d_model, 2).float()\n",
        "        denominator = torch.pow(10000, even_i/self.d_model)\n",
        "        position = (torch.arange(self.max_sequence_length)\n",
        "                          .reshape(self.max_sequence_length, 1))\n",
        "        even_PE = torch.sin(position / denominator)\n",
        "        odd_PE = torch.cos(position / denominator)\n",
        "        stacked = torch.stack([even_PE, odd_PE], dim=2)\n",
        "        PE = torch.flatten(stacked, start_dim=1, end_dim=2)\n",
        "        return PE"
      ],
      "metadata": {
        "id": "D91Da_nOWIrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def self_attention(q, k, v, mask=None):\n",
        "    d_k = q.size()[-1]\n",
        "    scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k)\n",
        "    print(f\"scaled.size() : {scaled.size()}\")\n",
        "    if mask is not None:\n",
        "        scaled = scaled.permute(1, 0, 2, 3) + mask\n",
        "        scaled = scaled.permute(1, 0, 2, 3)\n",
        "    attention = F.softmax(scaled, dim=-1)\n",
        "    values = torch.matmul(attention, v)\n",
        "    return values, attention\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_model // num_heads\n",
        "        self.qkv_layer = nn.Linear(d_model , 3 * d_model)\n",
        "        self.linear_layer = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        batch_size, max_sequence_length, d_model = x.size()\n",
        "        qkv = self.qkv_layer(x)\n",
        "        qkv = qkv.reshape(batch_size, max_sequence_length, self.num_heads, 3 * self.head_dim)\n",
        "        qkv = qkv.permute(0, 2, 1, 3)\n",
        "        q, k, v = qkv.chunk(3, dim=-1)\n",
        "        values, attention = self_attention(q, k, v, mask)\n",
        "        values = values.permute(0,2,1,3).reshape(batch_size, max_sequence_length, self.num_heads * self.head_dim)\n",
        "        out = self.linear_layer(values)\n",
        "        return out"
      ],
      "metadata": {
        "id": "YvZk94piXcoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNormalization(nn.Module):\n",
        "    def __init__(self, parameters_shape, eps=1e-5):\n",
        "        super().__init__()\n",
        "        self.parameters_shape=parameters_shape\n",
        "        self.eps=eps\n",
        "        self.gamma = nn.Parameter(torch.ones(parameters_shape))\n",
        "        self.beta =  nn.Parameter(torch.zeros(parameters_shape))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        dims = [-(i + 1) for i in range(len(self.parameters_shape))]\n",
        "        mean = inputs.mean(dim=dims, keepdim=True)\n",
        "        var = ((inputs - mean) ** 2).mean(dim=dims, keepdim=True)\n",
        "        std = (var + self.eps).sqrt()\n",
        "        y = (inputs - mean) / std\n",
        "        out = self.gamma * y  + self.beta\n",
        "        return out"
      ],
      "metadata": {
        "id": "jTgHJ15StIzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForwardNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, hidden, drop_prob=0.1):\n",
        "        super(FeedForwardNetwork, self).__init__()\n",
        "        self.linear1 = nn.Linear(d_model, hidden)\n",
        "        self.linear2 = nn.Linear(hidden, d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=drop_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "OKezgj1ItI_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, ffn_hidden, num_heads, drop_prob):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.attention = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n",
        "        self.norm1 = LayerNormalization(parameters_shape=[d_model])\n",
        "        self.dropout1 = nn.Dropout(p=drop_prob)\n",
        "        self.ffn = FeedForwardNetwork(d_model=d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n",
        "        self.norm2 = LayerNormalization(parameters_shape=[d_model])\n",
        "        self.dropout2 = nn.Dropout(p=drop_prob)\n",
        "\n",
        "    def forward(self, x, self_attention_mask):\n",
        "        residual_x = x.clone()\n",
        "        x = self.attention(x, mask=self_attention_mask)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.norm1(x + residual_x)\n",
        "        residual_x = x.clone()\n",
        "        x = self.ffn(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.norm2(x + residual_x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "JgBFSTpdtJCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SequentialEncoder(nn.Sequential):\n",
        "    def forward(self, *inputs):\n",
        "        x, self_attention_mask  = inputs\n",
        "        for module in self._modules.values():\n",
        "            x = module(x, self_attention_mask)\n",
        "        return x"
      ],
      "metadata": {
        "id": "AOjJ5QovttAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 d_model,\n",
        "                 ffn_hidden,\n",
        "                 num_heads,\n",
        "                 drop_prob,\n",
        "                 num_layers,\n",
        "                 max_sequence_length,\n",
        "                 language_to_index,\n",
        "                 START_TOKEN,\n",
        "                 END_TOKEN,\n",
        "                 PADDING_TOKEN):\n",
        "        super().__init__()\n",
        "        self.sentence_embedding = SentenceEmbedding(max_sequence_length, d_model, language_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN)   # tokenizer part - need to correct\n",
        "        self.layers = SequentialEncoder(*[EncoderLayer(d_model, ffn_hidden, num_heads, drop_prob)\n",
        "                                      for _ in range(num_layers)])\n",
        "\n",
        "    def forward(self, x, self_attention_mask, start_token, end_token):\n",
        "        x = self.sentence_embedding(x, start_token, end_token)\n",
        "        x = self.layers(x, self_attention_mask)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "9bBSFmZbl71F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SeqEncoder(nn.Module):\n",
        "    def __init__(self, d_model, ffn_hidden, num_heads, drop_prob, num_layers):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(*[EncoderLayer(d_model, ffn_hidden, num_heads, drop_prob)\n",
        "                                     for _ in range(num_layers)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layers(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "ZVoz-DUCtJE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadCrossAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_model // num_heads\n",
        "        self.kv_layer = nn.Linear(d_model , 2 * d_model)\n",
        "        self.q_layer = nn.Linear(d_model , d_model)\n",
        "        self.linear_layer = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, x, y, mask):\n",
        "        batch_size, sequence_length, d_model = x.size() # this comes from the Encoder outputs\n",
        "        kv = self.kv_layer(x)                           # We use this to make key and value matrices\n",
        "        q = self.q_layer(y)                             # This is the continuation outputs in the decoder layer\n",
        "        kv = kv.reshape(batch_size, sequence_length, self.num_heads, 2 * self.head_dim)\n",
        "        q = q.reshape(batch_size, sequence_length, self.num_heads, self.head_dim)\n",
        "        kv = kv.permute(0, 2, 1, 3)\n",
        "        q = q.permute(0, 2, 1, 3)\n",
        "        k, v = kv.chunk(2, dim=-1)\n",
        "        values, attention = self_attention(q, k, v, mask)\n",
        "        values = values.permute(0, 2, 1, 3).reshape(batch_size, sequence_length, d_model)\n",
        "        out = self.linear_layer(values)\n",
        "        return out"
      ],
      "metadata": {
        "id": "QrdoaYxuU0J2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, ffn_hidden, num_heads, drop_prob):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.self_attention = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n",
        "        self.layer_norm1 = LayerNormalization(parameters_shape=[d_model])\n",
        "        self.dropout1 = nn.Dropout(p=drop_prob)\n",
        "\n",
        "        self.encoder_decoder_attention = MultiHeadCrossAttention(d_model=d_model, num_heads=num_heads)\n",
        "        self.layer_norm2 = LayerNormalization(parameters_shape=[d_model])\n",
        "        self.dropout2 = nn.Dropout(p=drop_prob)\n",
        "\n",
        "        self.ffn = FeedForwardNetwork(d_model=d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n",
        "        self.layer_norm3 = LayerNormalization(parameters_shape=[d_model])\n",
        "        self.dropout3 = nn.Dropout(p=drop_prob)\n",
        "\n",
        "    def forward(self, x, y, self_attention_mask, cross_attention_mask):\n",
        "        _y = y.clone() # Residuals\n",
        "        y = self.self_attention(y, mask=self_attention_mask)\n",
        "        y = self.dropout1(y)\n",
        "        y = self.layer_norm1(y + _y)\n",
        "\n",
        "        _y = y.clone()\n",
        "        y = self.encoder_decoder_attention(x, y, mask=cross_attention_mask)\n",
        "        y = self.dropout2(y)\n",
        "        y = self.layer_norm2(y + _y)\n",
        "\n",
        "        _y = y.clone()\n",
        "        y = self.ffn(y)\n",
        "        y = self.dropout3(y)\n",
        "        y = self.layer_norm3(y + _y)\n",
        "        return y\n"
      ],
      "metadata": {
        "id": "L0lInNrmU0Mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SequentialDecoder(nn.Sequential):\n",
        "    def forward(self, *inputs):\n",
        "        x, y, self_attention_mask, cross_attention_mask = inputs\n",
        "        for module in self._modules.values():\n",
        "            y = module(x, y, self_attention_mask, cross_attention_mask)\n",
        "        return y"
      ],
      "metadata": {
        "id": "_Ua9rFBOU0PW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 d_model,\n",
        "                 ffn_hidden,\n",
        "                 num_heads,\n",
        "                 drop_prob,\n",
        "                 num_layers,\n",
        "                 max_sequence_length,\n",
        "                 language_to_index,\n",
        "                 START_TOKEN,\n",
        "                 END_TOKEN,\n",
        "                 PADDING_TOKEN):\n",
        "        super().__init__()\n",
        "        self.sentence_embedding = SentenceEmbedding(max_sequence_length, d_model, language_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN) # Need to add the tokenizer\n",
        "        self.layers = SequentialDecoder(*[DecoderLayer(d_model, ffn_hidden, num_heads, drop_prob) for _ in range(num_layers)])\n",
        "\n",
        "    def forward(self, x, y, self_attention_mask, cross_attention_mask, start_token, end_token):\n",
        "        y = self.sentence_embedding(y, start_token, end_token)\n",
        "        y = self.layers(x, y, self_attention_mask, cross_attention_mask)\n",
        "        return y"
      ],
      "metadata": {
        "id": "Jj_dKmXtU0Sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self,\n",
        "                d_model,\n",
        "                ffn_hidden,\n",
        "                num_heads,\n",
        "                drop_prob,\n",
        "                num_layers,\n",
        "                max_sequence_length,\n",
        "                kn_vocab_size,\n",
        "                english_to_index,\n",
        "                telugu_to_index,\n",
        "                START_TOKEN,\n",
        "                END_TOKEN,\n",
        "                PADDING_TOKEN\n",
        "                ):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(d_model, ffn_hidden, num_heads, drop_prob, num_layers, max_sequence_length, english_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN)\n",
        "        self.decoder = Decoder(d_model, ffn_hidden, num_heads, drop_prob, num_layers, max_sequence_length, telugu_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN)\n",
        "        self.linear = nn.Linear(d_model, kn_vocab_size)\n",
        "        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "    def forward(self,\n",
        "                x,\n",
        "                y,\n",
        "                encoder_self_attention_mask=None,\n",
        "                decoder_self_attention_mask=None,\n",
        "                decoder_cross_attention_mask=None,\n",
        "                enc_start_token=False,\n",
        "                enc_end_token=False,\n",
        "                dec_start_token=False, # We should make this true\n",
        "                dec_end_token=False): # x, y are batch of sentences\n",
        "        x = self.encoder(x, encoder_self_attention_mask, start_token=enc_start_token, end_token=enc_end_token)\n",
        "        out = self.decoder(x, y, decoder_self_attention_mask, decoder_cross_attention_mask, start_token=dec_start_token, end_token=dec_end_token)\n",
        "        out = self.linear(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "fWhxG4GuU0VY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVZQuRXlGtRO",
        "outputId": "ca7fcbb8-22ae-4a48-db71-2a52d7e3944f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F8rNB6OLGh7T"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "beLuOipvGiDu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "axXPRBFnGiGL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GX-YF9LaGiIs",
        "outputId": "e992dc56-acd1-4e5c-b108-895b88c34529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['for travel.',\n",
              " 'there was a body.',\n",
              " 'bigg boss is one of the biggest reality tv shows in india.',\n",
              " 'he said fresh dates of examinations would be notified later.',\n",
              " 'madhavan, anjali also acted in the movie along with anushka.']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYb1HDjEGiLk",
        "outputId": "4678d243-ff2c-4cf7-e378-52e735f76720"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['రైడ్ కోసం.',\n",
              " 'అక్కడ ఒక శవం కనబడింది.',\n",
              " 'బిగ్ బాస్ అనేది వరల్డ్స్ బిగ్గెస్ట్ రియాలిటీ షో.',\n",
              " 'మరల ఎప్పుడు పరీక్షలు నిర్వహిస్తామో అనేది త్వరలోనే వెల్లడిస్తాం అన్నారు.',\n",
              " 'ఈ చిత్రంలో అజయ్, ఇంద్రజ ఓ జంటగా, నాగశౌర్య, సనా మక్బుల్ మరో జంటగా నటించారు.']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "PERCENTILE = 97\n",
        "print( f\"{PERCENTILE}th percentile length telugu: {np.percentile([len(x) for x in telugu_sentences], PERCENTILE)}\" )\n",
        "print( f\"{PERCENTILE}th percentile length English: {np.percentile([len(x) for x in english_sentences], PERCENTILE)}\" )"
      ],
      "metadata": {
        "id": "QYT8guRkU0bL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b111691-9ee6-4e46-afa9-2594ed434b39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "97th percentile length telugu: 169.0\n",
            "97th percentile length English: 174.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sNCkrs29U0fK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d5d8c3c-4232-4008-f1f1-0b86a9ef0783"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentences: 4300000\n",
            "Number of valid sentences: 3252177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q9v9eoKAL8Hp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "telugu_sentences[-10:]"
      ],
      "metadata": {
        "id": "srXG2BumtqAL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df05ab97-0e73-4ed4-f2f0-ddbb7ab6e53e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['బి.ఎన్.సెహగల్',\n",
              " '30 మేర తగ్గింది.',\n",
              " 'పచ్చిపాలు : 2 టీస్పూన్లు',\n",
              " 'గుజరాత్ లో బిజెపికి కాంగ్రెస్ గట్టి పోటీ ఇస్తోంది.',\n",
              " 'కుడివైపు తిను',\n",
              " 'రైడ్ కోసం.',\n",
              " 'అక్కడ ఒక శవం కనబడింది.',\n",
              " 'బిగ్ బాస్ అనేది వరల్డ్స్ బిగ్గెస్ట్ రియాలిటీ షో.',\n",
              " 'మరల ఎప్పుడు పరీక్షలు నిర్వహిస్తామో అనేది త్వరలోనే వెల్లడిస్తాం అన్నారు.',\n",
              " 'ఈ చిత్రంలో అజయ్, ఇంద్రజ ఓ జంటగా, నాగశౌర్య, సనా మక్బుల్ మరో జంటగా నటించారు.']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "d_model = 512\n",
        "batch_size = 30\n",
        "ffn_hidden = 1024\n",
        "num_heads = 4\n",
        "drop_prob = 0.1\n",
        "num_layers = 1\n",
        "max_sequence_length = 200\n",
        "kn_vocab_size = len(telugu_vocabulary)\n",
        "\n",
        "transformer = Transformer(d_model,\n",
        "                          ffn_hidden,\n",
        "                          num_heads,\n",
        "                          drop_prob,\n",
        "                          num_layers,\n",
        "                          max_sequence_length,\n",
        "                          kn_vocab_size,\n",
        "                          english_to_index,\n",
        "                          telugu_to_index,\n",
        "                          START_TOKEN,\n",
        "                          END_TOKEN,\n",
        "                          PADDING_TOKEN)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "uws4Al0KMPiJ",
        "outputId": "cb27536e-763e-4d1b-e269-3213dda04234"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-edfe332d0b88>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mkn_vocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtelugu_vocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m transformer = Transformer(d_model, \n\u001b[0m\u001b[1;32m     13\u001b[0m                           \u001b[0mffn_hidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                           \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-6e6448a3e219>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, d_model, ffn_hidden, num_heads, drop_prob, num_layers, max_sequence_length, kn_vocab_size, english_to_index, kannada_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN)\u001b[0m\n\u001b[1;32m     15\u001b[0m                 ):\n\u001b[1;32m     16\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mffn_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_sequence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menglish_to_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTART_TOKEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEND_TOKEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPADDING_TOKEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mffn_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_sequence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkannada_to_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTART_TOKEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEND_TOKEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPADDING_TOKEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkn_vocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-d3152ee818ab>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, d_model, ffn_hidden, num_heads, drop_prob, num_layers, max_sequence_length, language_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN)\u001b[0m\n\u001b[1;32m     12\u001b[0m                  PADDING_TOKEN):\n\u001b[1;32m     13\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_sequence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage_to_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTART_TOKEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEND_TOKEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPADDING_TOKEN\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# tokenizer part - need to correct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         self.layers = SequentialEncoder(*[EncoderLayer(d_model, ffn_hidden, num_heads, drop_prob)\n\u001b[1;32m     16\u001b[0m                                       for _ in range(num_layers)])\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SentenceEmbedding' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "criterian = nn.CrossEntropyLoss(ignore_index=kannada_to_index[PADDING_TOKEN],\n",
        "                                reduction='none')\n",
        "\n",
        "# When computing the loss, we are ignoring cases when the label is the padding token\n",
        "for params in transformer.parameters():                    # Xavier initialization helps in better convergence during training.\n",
        "    if params.dim() > 1:\n",
        "        nn.init.xavier_uniform_(params)               #helps to prevent vanishing or exploding gradients during training.\n",
        "\n",
        "optim = torch.optim.Adam(transformer.parameters(), lr=1e-4)\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "metadata": {
        "id": "l_7gFepUMPk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i5Datx7jMPny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uktr8DLAMPqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T3pEJeBcMPtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5f0DmVYiMPv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "06I8tPkHMPym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0K3uTm1wMP1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "upVsinqaMP4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YurkHNEGMP7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xPIJEH-7MP9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking whether individual functions working or not"
      ],
      "metadata": {
        "id": "AQmpttw3tqCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_model = 512\n",
        "num_heads = 8\n",
        "drop_prob = 0.1\n",
        "batch_size = 30\n",
        "max_sequence_length = 200\n",
        "ffn_hidden = 2048\n",
        "num_layers = 5\n",
        "\n",
        "# encoder = Encoder(d_model, ffn_hidden, num_heads, drop_prob, num_layers)"
      ],
      "metadata": {
        "id": "Z80btmc1tJHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "look_ahead_mask = torch.full([max_sequence_length, max_sequence_length], True)\n",
        "look_ahead_mask = torch.triu(look_ahead_mask, diagonal=1)\n",
        "look_ahead_mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9YYKl79MP_4",
        "outputId": "cba66230-b4e7-4c75-f2da-d654a3285128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False,  True,  True,  ...,  True,  True,  True],\n",
              "        [False, False,  True,  ...,  True,  True,  True],\n",
              "        [False, False, False,  ...,  True,  True,  True],\n",
              "        ...,\n",
              "        [False, False, False,  ..., False,  True,  True],\n",
              "        [False, False, False,  ..., False, False,  True],\n",
              "        [False, False, False,  ..., False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn( (batch_size, max_sequence_length, d_model) ) # includes positional encoding\n",
        "out = encoder(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XcEM5lxtJLB",
        "outputId": "432215b7-32d3-4700-dc68-ef862ad72ecd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- ATTENTION 1 ------\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "qkv.size(): torch.Size([30, 200, 1536])\n",
            "qkv.size(): torch.Size([30, 200, 8, 192])\n",
            "qkv.size(): torch.Size([30, 8, 200, 192])\n",
            "q size: torch.Size([30, 8, 200, 64]), k size: torch.Size([30, 8, 200, 64]), v size: torch.Size([30, 8, 200, 64]), \n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "values.size(): torch.Size([30, 8, 200, 64]), attention.size:torch.Size([30, 8, 200, 200]) \n",
            "values.size(): torch.Size([30, 200, 512])\n",
            "out.size(): torch.Size([30, 200, 512])\n",
            "------- DROPOUT 1 ------\n",
            "------- ADD AND LAYER NORMALIZATION 1 ------\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "------- ATTENTION 2 ------\n",
            "x after first linear layer: torch.Size([30, 200, 2048])\n",
            "x after activation: torch.Size([30, 200, 2048])\n",
            "x after dropout: torch.Size([30, 200, 2048])\n",
            "x after 2nd linear layer: torch.Size([30, 200, 512])\n",
            "------- DROPOUT 2 ------\n",
            "------- ADD AND LAYER NORMALIZATION 2 ------\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "------- ATTENTION 1 ------\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "qkv.size(): torch.Size([30, 200, 1536])\n",
            "qkv.size(): torch.Size([30, 200, 8, 192])\n",
            "qkv.size(): torch.Size([30, 8, 200, 192])\n",
            "q size: torch.Size([30, 8, 200, 64]), k size: torch.Size([30, 8, 200, 64]), v size: torch.Size([30, 8, 200, 64]), \n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "values.size(): torch.Size([30, 8, 200, 64]), attention.size:torch.Size([30, 8, 200, 200]) \n",
            "values.size(): torch.Size([30, 200, 512])\n",
            "out.size(): torch.Size([30, 200, 512])\n",
            "------- DROPOUT 1 ------\n",
            "------- ADD AND LAYER NORMALIZATION 1 ------\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "------- ATTENTION 2 ------\n",
            "x after first linear layer: torch.Size([30, 200, 2048])\n",
            "x after activation: torch.Size([30, 200, 2048])\n",
            "x after dropout: torch.Size([30, 200, 2048])\n",
            "x after 2nd linear layer: torch.Size([30, 200, 512])\n",
            "------- DROPOUT 2 ------\n",
            "------- ADD AND LAYER NORMALIZATION 2 ------\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "------- ATTENTION 1 ------\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "qkv.size(): torch.Size([30, 200, 1536])\n",
            "qkv.size(): torch.Size([30, 200, 8, 192])\n",
            "qkv.size(): torch.Size([30, 8, 200, 192])\n",
            "q size: torch.Size([30, 8, 200, 64]), k size: torch.Size([30, 8, 200, 64]), v size: torch.Size([30, 8, 200, 64]), \n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "values.size(): torch.Size([30, 8, 200, 64]), attention.size:torch.Size([30, 8, 200, 200]) \n",
            "values.size(): torch.Size([30, 200, 512])\n",
            "out.size(): torch.Size([30, 200, 512])\n",
            "------- DROPOUT 1 ------\n",
            "------- ADD AND LAYER NORMALIZATION 1 ------\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "------- ATTENTION 2 ------\n",
            "x after first linear layer: torch.Size([30, 200, 2048])\n",
            "x after activation: torch.Size([30, 200, 2048])\n",
            "x after dropout: torch.Size([30, 200, 2048])\n",
            "x after 2nd linear layer: torch.Size([30, 200, 512])\n",
            "------- DROPOUT 2 ------\n",
            "------- ADD AND LAYER NORMALIZATION 2 ------\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "------- ATTENTION 1 ------\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "qkv.size(): torch.Size([30, 200, 1536])\n",
            "qkv.size(): torch.Size([30, 200, 8, 192])\n",
            "qkv.size(): torch.Size([30, 8, 200, 192])\n",
            "q size: torch.Size([30, 8, 200, 64]), k size: torch.Size([30, 8, 200, 64]), v size: torch.Size([30, 8, 200, 64]), \n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "values.size(): torch.Size([30, 8, 200, 64]), attention.size:torch.Size([30, 8, 200, 200]) \n",
            "values.size(): torch.Size([30, 200, 512])\n",
            "out.size(): torch.Size([30, 200, 512])\n",
            "------- DROPOUT 1 ------\n",
            "------- ADD AND LAYER NORMALIZATION 1 ------\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "------- ATTENTION 2 ------\n",
            "x after first linear layer: torch.Size([30, 200, 2048])\n",
            "x after activation: torch.Size([30, 200, 2048])\n",
            "x after dropout: torch.Size([30, 200, 2048])\n",
            "x after 2nd linear layer: torch.Size([30, 200, 512])\n",
            "------- DROPOUT 2 ------\n",
            "------- ADD AND LAYER NORMALIZATION 2 ------\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "------- ATTENTION 1 ------\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "qkv.size(): torch.Size([30, 200, 1536])\n",
            "qkv.size(): torch.Size([30, 200, 8, 192])\n",
            "qkv.size(): torch.Size([30, 8, 200, 192])\n",
            "q size: torch.Size([30, 8, 200, 64]), k size: torch.Size([30, 8, 200, 64]), v size: torch.Size([30, 8, 200, 64]), \n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "values.size(): torch.Size([30, 8, 200, 64]), attention.size:torch.Size([30, 8, 200, 200]) \n",
            "values.size(): torch.Size([30, 200, 512])\n",
            "out.size(): torch.Size([30, 200, 512])\n",
            "------- DROPOUT 1 ------\n",
            "------- ADD AND LAYER NORMALIZATION 1 ------\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "------- ATTENTION 2 ------\n",
            "x after first linear layer: torch.Size([30, 200, 2048])\n",
            "x after activation: torch.Size([30, 200, 2048])\n",
            "x after dropout: torch.Size([30, 200, 2048])\n",
            "x after 2nd linear layer: torch.Size([30, 200, 512])\n",
            "------- DROPOUT 2 ------\n",
            "------- ADD AND LAYER NORMALIZATION 2 ------\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rU1lm8IXSWw"
      },
      "outputs": [],
      "source": [
        "q = np.random.randn(L,dim)\n",
        "k = np.random.randn(L,dim)\n",
        "v = np.random.randn(L,dim)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hP2OQsvYNBp",
        "outputId": "d2a4acf1-7487-45ac-ef4c-fcc006f51119"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.12591538, -0.20853284, -1.43566048,  0.16828876, -1.78339133,\n",
              "         1.75671274,  0.48905883,  0.68204429],\n",
              "       [ 0.17048747, -1.00515842,  0.98210632, -0.22148951, -0.68260914,\n",
              "        -1.96552464, -1.51216378, -1.09425526],\n",
              "       [-0.35344463,  1.41034386,  0.83618775, -0.98560087, -0.97709445,\n",
              "         1.32576395, -0.39526458,  2.8772897 ],\n",
              "       [ 1.65734447,  0.48862427,  1.12218185,  0.18465231, -0.62060722,\n",
              "         0.39032771, -1.01891697,  1.69876902]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "  return (np.exp(x).T / np.sum(np.exp(x), axis=-1)).T"
      ],
      "metadata": {
        "id": "gC3PPZs5bbDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def self_attn(q,k,v,mask = None):\n",
        "  temp = np.matmul(q,k.T)/math.sqrt(q[-1])\n",
        "  sc = temp+mask\n",
        "  return np.matmul(softmax(sc),v)\n"
      ],
      "metadata": {
        "id": "0v9seuzPYOAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xconA66afUT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# multihead attention"
      ],
      "metadata": {
        "id": "78-yMk4fgN_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 2\n",
        "seq = 5\n",
        "in_dim = 512\n",
        "out_dim = 512\n",
        "x = torch.randn(batch_size,seq,in_dim)\n",
        "x.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_Vyl6dlgOCS",
        "outputId": "89a5d26f-cf4a-4993-9041-6d76c9804200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 5, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qkv_layer = nn.Linear(in_dim,out_dim*3)\n",
        "qkv = qkv_layer(x)\n",
        "qkv.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bEmBlM5gOEq",
        "outputId": "6469bfbb-a517-45f8-ad35-03ce11e6d0f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 5, 1536])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "heads = 8\n",
        "head_dim = in_dim//8\n",
        "qkv = qkv.reshape(batch_size,seq,heads,head_dim*3)\n",
        "qkv.size() # batch size, no of words, no of attention heads, each attention head dimension"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbx4bQJ2gOHi",
        "outputId": "f607e685-ddc0-4bf0-9012-27e309b9901f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 5, 8, 192])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qkv = qkv.permute(0,2,1,3)\n",
        "qkv.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbF2O1kbgOJ6",
        "outputId": "452d1da7-8727-49b8-b409-f104758cbafe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 8, 5, 192])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q,k,v = qkv.chunk(3,dim = -1)\n",
        "q.size(),k.size(),v.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3ZYvWLXgOOS",
        "outputId": "65d92c2b-6e86-4ae5-9e69-41599a28705f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 8, 5, 64]),\n",
              " torch.Size([2, 8, 5, 64]),\n",
              " torch.Size([2, 8, 5, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled = torch.matmul(q,k.transpose(-2,-1))/math.sqrt(q.size()[-1])\n",
        "scaled.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtVYjc7LgORD",
        "outputId": "2562f9d8-2973-4f6e-dc98-929b13c3c397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 8, 5, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention = F.softmax(scaled,dim = -1)"
      ],
      "metadata": {
        "id": "R5tskgZzgOUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values = torch.matmul(attention,v)\n",
        "values.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkOKWMeHgOXq",
        "outputId": "e596314d-c33c-46c9-9916-debb0e5a3248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 8, 5, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "values = values.reshape(batch_size,seq,heads*head_dim)\n",
        "values.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "el5pHuUrgOab",
        "outputId": "ae9b4863-fc79-436a-dc51-8a58f6239fd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 5, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "WrUR9ChQouM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VkBDhVmIeo1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dZSKl9C1eo4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wisAb-nAeo7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'మళ్లీ ఉదయిస్తాడు.'\n",
        "list(text)"
      ],
      "metadata": {
        "id": "0CQKN9NWeo-M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0eaef79-6054-4404-8571-6d643cc828b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['మ',\n",
              " 'ళ',\n",
              " '్',\n",
              " 'ల',\n",
              " 'ీ',\n",
              " ' ',\n",
              " 'ఉ',\n",
              " 'ద',\n",
              " 'య',\n",
              " 'ి',\n",
              " 'స',\n",
              " '్',\n",
              " 'త',\n",
              " 'ా',\n",
              " 'డ',\n",
              " 'ు',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xBx1JoWgepD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class Encoder(nn.Module):\n",
        "  # def __init(self,num_layers,d_model,num_heads,ffn_hidden,drop_prob):"
      ],
      "metadata": {
        "id": "fzzUqqqhepHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_model = 512\n",
        "num_heads = 8\n",
        "drop_prob = 0.1\n",
        "batch_size = 30\n",
        "max_sequence_length = 20\n",
        "ffn_hidden = 1024\n",
        "num_layers = 2\n",
        "\n",
        "# encoder = Encoder(d_model, ffn_hidden, num_heads, drop_prob, num_layers)"
      ],
      "metadata": {
        "id": "DnKdn6RmepKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v07KLPhfepNE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}